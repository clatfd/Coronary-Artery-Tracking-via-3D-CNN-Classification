{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for artery tracking \n",
    "#simplified from 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import datetime\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN Tracker\n",
    "import sys\n",
    "sys.path.append(r'U:\\LiChen\\AICafe\\CNNTracker')\n",
    "from models.centerline_net import CenterlineNet\n",
    "from centerline_train_tools.data_provider_argu import DataGenerater\n",
    "from centerline_train_tools.centerline_trainner import Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import iCafe Python\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(r'\\\\DESKTOP2\\Ftensorflow\\LiChen\\iCafe')\n",
    "sys.path.insert(0,r'\\\\DESKTOP4\\Dtensorflow\\LiChen\\iCafePython')\n",
    "from iCafePython import iCafe\n",
    "from iCafePython import SnakeList,Snake,SWCNode,Point3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CNNTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only need to select one model\n",
    "#Model 1 CNN tracker for ICA TOF MRA\n",
    "swc_name = 'cnn_snake'\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'U:\\LiChen\\AICafe\\CNNTracker')\n",
    "from models.centerline_net import CenterlineNet\n",
    "\n",
    "max_points = 500\n",
    "prob_thr = 0.85\n",
    "\n",
    "infer_model = CenterlineNet(n_classes=max_points)\n",
    "checkpoint_path_infer = r\"D:\\tensorflow\\LiChen\\AICafe\\CNNTracker\\CNNTracker1-1\\classification_checkpoints\\centerline_net_model_Epoch_29.pkl\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path_infer)\n",
    "net_dict = checkpoint['net_dict']\n",
    "infer_model.load_state_dict(net_dict)\n",
    "infer_model.to(device)\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 CNN tracker for Coronary CTA\n",
    "swc_name = 'cnn_snake'\n",
    "max_points = 500\n",
    "prob_thr = 0.85\n",
    "\n",
    "infer_model = CenterlineNet(n_classes=max_points)\n",
    "\n",
    "checkpoint_path_infer = r\"D:\\tensorflow\\LiChen\\AICafe\\CNNTracker\\CNNTracker2-1\\classification_checkpoints\\centerline_net_model_Epoch_81.pkl\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path_infer)\n",
    "net_dict = checkpoint['net_dict']\n",
    "infer_model.load_state_dict(net_dict)\n",
    "infer_model.to(device)\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 CNN tracker for LATTE\n",
    "swc_name = 'cnn_snake'\n",
    "max_points = 500\n",
    "prob_thr = 0.85\n",
    "\n",
    "infer_model = CenterlineNet(n_classes=max_points)\n",
    "checkpoint_path_infer = r\"D:\\tensorflow\\LiChen\\AICafe\\CNNTracker\\CNNTracker4-1\\classification_checkpoints\\centerline_net_model_Epoch_99.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path_infer)\n",
    "net_dict = checkpoint['net_dict']\n",
    "infer_model.load_state_dict(net_dict)\n",
    "infer_model.to(device)\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'BRAVEAI'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "seg_model_name = 'LumenSeg2-3'\n",
    "\n",
    "with open(icafe_dir+'/'+dbname+'/db.list','rb') as fp:\n",
    "    dblist = pickle.load(fp)\n",
    "train_list = dblist['train']\n",
    "val_list = dblist['val']\n",
    "test_list = dblist['test']\n",
    "pilist = [pi.split('/')[1] for pi in dblist['test']]\n",
    "len(pilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'RotterdanCoronary'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "pilist = ['0_dataset05_U']\n",
    "seg_model_name = 'CoronarySeg1-8-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'UNC'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "seg_model_name = 'LumenSeg5-1'\n",
    "with open(icafe_dir+'/'+dbname+'/db.list','rb') as fp:\n",
    "    dblist = pickle.load(fp)\n",
    "pilist = [pi.split('/')[1] for pi in dblist['test']]\n",
    "len(pilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'HarborViewT1Pre'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "pilist = ['0_ID%d_U'%i for i in [2,9,10,11,12]]\n",
    "len(pilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE \n",
    "dbname = 'CAREIIMERGEGT'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "seg_model_name = 'LumenSeg6-1'\n",
    "with open(icafe_dir+'/'+dbname+'/db.list','rb') as fp:\n",
    "    dblist = pickle.load(fp)\n",
    "pilist = [pi.split('/')[1] for pi in dblist['test']]\n",
    "len(pilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'IPH-Sup-TOF-FullCoverage'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "seg_model_name = 'LumenSeg7-1'\n",
    "dblist_name = icafe_dir+'/'+dbname+'/db.list'\n",
    "\n",
    "with open(dblist_name,'rb') as fp:\n",
    "    dblist = pickle.load(fp)\n",
    "        \n",
    "pilist = [pi.split('/')[1] for pi in dblist['test']]\n",
    "len(pilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'WALLIAI'\n",
    "icafe_dir = r'\\\\DESKTOP2\\GiCafe\\result/'\n",
    "seg_model_name = 'LumenSeg8-1'\n",
    "dblist_name = icafe_dir+'/'+dbname+'/db.list'\n",
    "\n",
    "with open(dblist_name,'rb') as fp:\n",
    "    dblist = pickle.load(fp)\n",
    "        \n",
    "pilist = [pi.split('/')[1] for pi in dblist['test']]\n",
    "len(pilist),pilist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from s.whole.modelname to swc traces\n",
    "from iCafePython.connect.ext import extSnake\n",
    "import SimpleITK as sitk\n",
    "\n",
    "#redo artery tracing\n",
    "RETRACE = 1\n",
    "#redo artery tree contraint\n",
    "RETREE = 1\n",
    "\n",
    "#segmentation src\n",
    "seg_src = 's.whole.'+seg_model_name\n",
    "\n",
    "#Lumen segmentation threshold. \n",
    "# Lower value will cause too many noise branches, and neighboring branches will merge as one\n",
    "# Higher value will reduce the traces detectable\n",
    "SEGTHRES = 0.5\n",
    "\n",
    "#max search range in merge/branch, unit in mm\n",
    "# Higher value will allow larger gap and merge parts of broken arteries, \n",
    "#  but will also force noise branches to be merged in the tree\n",
    "search_range_thres = 10\n",
    "\n",
    "#which ves to build graph for artery labeling\n",
    "graph_ves = 'seg_ves_ext_tree2'\n",
    "\n",
    "DEBUG = 0\n",
    "\n",
    "\n",
    "for pi in pilist[20:19:-1]:\n",
    "    print('='*10,'Start processing',pilist.index(pi),'/',len(pilist),pi,'='*10)\n",
    "    if not os.path.exists(icafe_dir+'/'+dbname+'/'+pi):\n",
    "        os.mkdir(icafe_dir+'/'+dbname+'/'+pi)\n",
    "        \n",
    "    icafem = iCafe(icafe_dir+'/'+dbname+'/'+pi)\n",
    "    \n",
    "    #select correct version of s.whole from potentially multiple segmentation versions and save as s.whole\n",
    "    icafem.loadImg(seg_src)\n",
    "    icafem.saveImg('s.whole',icafem.I[seg_src],np.float16)\n",
    "    icafem.loadImg('s.whole')\n",
    "\n",
    "    #export v.tif for 3d visualization if icafe project does not have one already\n",
    "    if 'v' not in icafem.listAvailImgs():\n",
    "        vimg = copy.copy(icafem.I['s.whole'])\n",
    "        vimg[vimg<0] = 0\n",
    "        vimg = (vimg*255).astype(np.uint16)\n",
    "        icafem.saveImg('v',vimg,np.int16)\n",
    "        \n",
    "    #Tracing\n",
    "    if RETRACE or not icafem.existPath('seg_ves_ext.swc'):\n",
    "        if 's.whole' not in icafem.I:\n",
    "            icafem.loadImg('s.whole')\n",
    "        seg_ves_snakelist = icafem.constructSkeleton(icafem.I['s.whole']>SEGTHRES)\n",
    "        \n",
    "        #load image\n",
    "        file_name = icafem.getPath('o')\n",
    "        re_spacing_img = sitk.GetArrayFromImage(sitk.ReadImage(file_name))\n",
    "\n",
    "        seg_ves_snakelist = icafem.readSnake('seg_ves')\n",
    "        seg_ves_ext_snakelist = extSnake(seg_ves_snakelist,infer_model,re_spacing_img,DEBUG=DEBUG)\n",
    "        icafem.writeSWC('seg_ves_ext',seg_ves_ext_snakelist)\n",
    "    else:\n",
    "        seg_ves_ext_snakelist = icafem.readSnake('seg_ves_ext')\n",
    "        print('read from existing seg ves ext')\n",
    "    if seg_ves_ext_snakelist.NSnakes==0:\n",
    "        print('no snake found in seg ves, abort',pi)\n",
    "        continue\n",
    "    \n",
    "    if RETREE or not icafem.existPath('seg_ves_ext_tree.swc'):\n",
    "        if 's.whole' not in icafem.I:\n",
    "            icafem.loadImg('s.whole')\n",
    "        if icafem.xml.res is None:\n",
    "            icafem.xml.setResolution(0.296875)\n",
    "            icafem.xml.writexml()\n",
    "        tree_snakelist = seg_ves_ext_snakelist.tree(icafem,search_range=search_range_thres/icafem.xml.res,int_src='o',DEBUG=DEBUG)\n",
    "        icafem.writeSWC('seg_ves_ext_tree', tree_snakelist)\n",
    "        tree_snakelist = tree_snakelist.tree(icafem,search_range=search_range_thres/3/icafem.xml.res,int_src='s.whole',DEBUG=DEBUG)\n",
    "        icafem.writeSWC('seg_ves_ext_tree2', tree_snakelist)\n",
    "        \n",
    "        tree_main_snakelist = tree_snakelist.mainArtTree(dist_thres=10)\n",
    "        icafem.writeSWC('seg_ves_ext_tree2_main',tree_main_snakelist)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artery labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iCafePython.artlabel.artlabel import ArtLabel\n",
    "art_label_predictor = ArtLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pi in pilist[:]:\n",
    "    print('='*10,'Start processing',pilist.index(pi),'/',len(pilist),pi,'='*10)\n",
    "    if not os.path.exists(icafe_dir+'/'+dbname+'/'+pi):\n",
    "        os.mkdir(icafe_dir+'/'+dbname+'/'+pi)\n",
    "        \n",
    "    icafem = iCafe(icafe_dir+'/'+dbname+'/'+pi)\n",
    "    \n",
    "    #generate (simplified node!=2) graph for GNN art labeling\n",
    "    G = icafem.generateGraph(graph_ves,None,graphtype='graphsim', mode='test', trim=1)\n",
    "    if len(G.nodes())<5:\n",
    "        print('too few snakes for artlabeling')\n",
    "        continue\n",
    "    icafem.writeGraph(G,graphtype='graphsim')\n",
    "\n",
    "    #predict landmarks\n",
    "    pred_landmark, ves_end_pts = art_label_predictor.pred(icafem.getPath('graphsim'),icafem.xml.res)\n",
    "    #complete graph Gcom for finding the pts in the path\n",
    "    Gcom = icafem.generateGraph(graph_ves, None, graphtype='graphcom')\n",
    "    ves_snakelist = findSnakeFromPts(Gcom,G,ves_end_pts)\n",
    "    print('@@@predict',len(pred_landmark),'landmarks',ves_snakelist)\n",
    "    #save landmark and ves\n",
    "    icafem.xml.landmark = pred_landmark\n",
    "    icafem.xml.writexml()\n",
    "    icafem.writeSWC('ves_pred', ves_snakelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vimg = vimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(vimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icafem.saveImg('v',vimg,np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "a = tifffile.imread(r\"\\\\DESKTOP2\\GiCafe\\result\\WALLI\\47_WALLI-V-09-1-B_M\\TH_47_WALLI-V-09-1-B_Mv.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(a[118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_simple(snakelist):\n",
    "    snakelist = copy.deepcopy(snakelist)\n",
    "    _ = snakelist.resampleSnakes(1)\n",
    "    #ground truth snakelist from icafem.veslist\n",
    "    all_metic = snakelist.motMetric(icafem.veslist)\n",
    "    metric_dict = all_metic.metrics(['MOTA','IDF1','MOTP','IDS'])\n",
    "    #ref_snakelist = icafem.readSnake('ves')\n",
    "    snakelist.compRefSnakelist(icafem.vessnakelist)\n",
    "    metric_dict['OV'], metric_dict['OF'], metric_dict['OT'], metric_dict['AI'], metric_dict['UM'], metric_dict['UMS'], metric_dict['ref_UM'], metric_dict['ref_UMS'], metric_dict['mean_diff'] = snakelist.evalCompDist()\n",
    "    str = ''\n",
    "    metric_dict_simple = ['MOTA','IDF1','MOTP','IDS','OV']\n",
    "    for key in metric_dict_simple:\n",
    "        str += key+'\\t'\n",
    "    str += '\\n'\n",
    "    for key in metric_dict_simple:\n",
    "        if type(metric_dict[key]) == int:\n",
    "            str += '%d\\t'%metric_dict[key]\n",
    "        else:\n",
    "            str += '%.3f\\t'%metric_dict[key]\n",
    "    print(str)\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metric and save in each pi folder\n",
    "REFEAT = 0\n",
    "for pi in pilist[:1]:\n",
    "    print('='*10,'Start processing',pilist.index(pi),'/',len(pilist),pi,'='*10)\n",
    "        \n",
    "    icafem = iCafe(icafe_dir+'/'+pi)\n",
    "    \n",
    "    if REFEAT or not icafem.existPath('metric.pickle'):\n",
    "        print('init metric')\n",
    "        all_metric_dict = {}\n",
    "    else:\n",
    "        print('load metric')\n",
    "        with open(icafem.getPath('metric.pickle'),'rb') as fp:\n",
    "            all_metric_dict = pickle.load(fp)\n",
    "    \n",
    "    for vesname in ['seg_ves_ext_tree2_main']:\n",
    "    #for vesname in ['seg_raw','seg_ves_ext_main','seg_ves_ext_tree2']:\n",
    "    #comparison methods\n",
    "    #for vesname in ['frangi_ves','seg_unet','seg_raw','raw_sep','cnn_snake','dcat_snake','seg_ves_ext_tree2_main']:\n",
    "        if vesname in all_metric_dict:\n",
    "            continue\n",
    "        print('-'*10,vesname,'-'*10)\n",
    "        pred_snakelist = icafem.readSnake(vesname)\n",
    "        if pred_snakelist.NSnakes==0:\n",
    "            print('no snake',pi,vesname)\n",
    "            continue\n",
    "        all_metric_dict[vesname] = eval_simple(pred_snakelist.resampleSnakes(1))\n",
    "        \n",
    "    with open(icafem.getPath('metric.pickle'),'wb') as fp:\n",
    "        pickle.dump(all_metric_dict,fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check feat\n",
    "pi = pilist[0]\n",
    "icafem = iCafe(icafe_dir+'/'+pi)\n",
    "with open(icafem.getPath('metric.pickle'),'rb') as fp:\n",
    "    all_metric_dict = pickle.load(fp)\n",
    "all_metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect feats from pickle\n",
    "eval_vesname = {'frangi_ves':'Frangi','seg_unet':'U-Net','seg_raw':'DDT',\n",
    "                'raw_sep':'iCafe','cnn_snake':'CNN Tracker','dcat_snake':'DCAT','seg_ves_ext_tree2_main':'DOST (ours)',\n",
    "               'seg_ves':'DOST (initial curve)','seg_ves_ext_main':'DOST (deep snake)','seg_ves_ext_tree2':'DOST tree'}\n",
    "feats = {}\n",
    "for vesname in eval_vesname:\n",
    "    feats[vesname] = {}\n",
    "    \n",
    "for pi in pilist[:]:\n",
    "    icafem = iCafe(icafe_dir+'/'+dbname+'/'+pi)\n",
    "    if not icafem.existPath('metric.pickle'):\n",
    "        continue\n",
    "        \n",
    "    with open(icafem.getPath('metric.pickle'),'rb') as fp:\n",
    "        all_metric_dict = pickle.load(fp)\n",
    "    \n",
    "    #for vesname in all_metric_dict:\n",
    "    for vesname in eval_vesname:\n",
    "        if vesname not in all_metric_dict:\n",
    "            print('no',vesname,'in',pi)\n",
    "            continue\n",
    "        for metric in all_metric_dict[vesname]:\n",
    "            if metric not in feats[vesname]:\n",
    "                feats[vesname][metric] = []\n",
    "            feats[vesname][metric].append(all_metric_dict[vesname][metric]) \n",
    "    \n",
    "\n",
    "sel_metrics = ['OV','AI', 'MOTA', 'IDF1', 'IDS']\n",
    "print('\\t'.join(['']+sel_metrics))\n",
    "for vesname in feats:\n",
    "    featstr = eval_vesname[vesname]+'\\t'\n",
    "    for metric in sel_metrics:\n",
    "        if metric in ['IDS']:\n",
    "            featstr += '%.1f\\t'%np.mean(feats[vesname][metric])            \n",
    "        else:\n",
    "            featstr += '%.3f\\t'%np.mean(feats[vesname][metric])\n",
    "    print(featstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:centerlineNet]",
   "language": "python",
   "name": "conda-env-centerlineNet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
